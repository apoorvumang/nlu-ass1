{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.functional as F\n",
    "import torch.nn.functional as F\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "corpus = [\n",
    "    'he is a king',\n",
    "    'she is a queen',\n",
    "    'he is a man',\n",
    "    'she is a woman',\n",
    "    'warsaw is poland capital',\n",
    "    'berlin is germany capital',\n",
    "    'paris is france capital',   \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['he', 'is', 'a', 'king'], ['she', 'is', 'a', 'queen'], ['he', 'is', 'a', 'man'], ['she', 'is', 'a', 'woman'], ['warsaw', 'is', 'poland', 'capital'], ['berlin', 'is', 'germany', 'capital'], ['paris', 'is', 'france', 'capital']]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_corpus(corpus):\n",
    "    tokens = [x.split() for x in corpus]\n",
    "    return tokens\n",
    "\n",
    "tokenized_corpus = tokenize_corpus(corpus)\n",
    "print(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for sentence in tokenized_corpus:\n",
    "    for token in sentence:\n",
    "        if token not in vocabulary:\n",
    "            vocabulary.append(token)\n",
    "\n",
    "word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
    "idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
    "\n",
    "vocabulary_size = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "window_size = 2\n",
    "idx_pairs = []\n",
    "# for each sentence\n",
    "for sentence in tokenized_corpus:\n",
    "    indices = [word2idx[word] for word in sentence]\n",
    "    # for each word, threated as center word\n",
    "    for center_word_pos in range(len(indices)):\n",
    "        # for each window position\n",
    "        for w in range(-window_size, window_size + 1):\n",
    "            context_word_pos = center_word_pos + w\n",
    "            # make soure not jump out sentence\n",
    "            if context_word_pos < 0 or context_word_pos >= len(indices) or center_word_pos == context_word_pos:\n",
    "                continue\n",
    "            context_word_idx = indices[context_word_pos]\n",
    "            idx_pairs.append((indices[center_word_pos], context_word_idx))\n",
    "\n",
    "idx_pairs = np.array(idx_pairs) # it will be useful to have this as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_layer(word_idx):\n",
    "    x = torch.zeros(vocabulary_size).float()\n",
    "    x[word_idx] = 1.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epo =0 loss = 3.83390862260546\n",
      "epo =10 loss = 2.752981013911111\n",
      "epo =20 loss = 2.4478960990905763\n",
      "epo =30 loss = 2.2490220512662615\n",
      "epo =40 loss = 2.0967302407537187\n",
      "epo =50 loss = 1.9795851520129613\n",
      "epo =60 loss = 1.8949202265058245\n",
      "epo =70 loss = 1.8356305922780718\n",
      "epo =80 loss = 1.7933225870132445\n",
      "epo =90 loss = 1.7619091647011893\n"
     ]
    }
   ],
   "source": [
    "embedding_dims = 5\n",
    "W1 = Variable(torch.randn(embedding_dims, vocabulary_size).float(), requires_grad=True)\n",
    "W2 = Variable(torch.randn(vocabulary_size, embedding_dims).float(), requires_grad=True)\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "for epo in range(num_epochs):\n",
    "    loss_val = 0\n",
    "    for data, target in idx_pairs:\n",
    "        x = Variable(get_input_layer(data)).float()\n",
    "        y_true = Variable(torch.from_numpy(np.array([target])).long())\n",
    "\n",
    "        z1 = torch.matmul(W1, x)\n",
    "        z2 = torch.matmul(W2, z1)\n",
    "    \n",
    "        log_softmax = F.log_softmax(z2, dim=0)\n",
    "\n",
    "        loss = F.nll_loss(log_softmax.view(1,-1), y_true)\n",
    "        loss_val += loss.item()\n",
    "        loss.backward()\n",
    "        W1.data -= learning_rate * W1.grad.data\n",
    "        W2.data -= learning_rate * W2.grad.data\n",
    "\n",
    "        W1.grad.data.zero_()\n",
    "        W2.grad.data.zero_()\n",
    "    if epo % 10 == 0:\n",
    "        print('epo =' + str(epo), 'loss = ' + str(loss_val/len(idx_pairs)))\n",
    "#         print(f'Loss at epo {epo}: {loss_val/len(idx_pairs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6650, -0.6515,  1.7643, -0.6612, -0.5184,  0.1936, -0.7601,  1.1543,\n",
      "          0.0982,  1.0659,  1.0329,  0.8713, -1.1771,  1.2245, -0.0804],\n",
      "        [-0.7244,  0.0624,  0.6872, -0.3318, -0.5093,  0.6087, -0.5052,  1.7931,\n",
      "          0.3268, -0.1901,  0.4482, -0.5657, -2.5397, -0.2461, -1.9045],\n",
      "        [-1.6269, -0.6633, -0.5409, -0.9472, -1.5115, -0.0293, -1.1832, -0.0305,\n",
      "          0.3386, -1.2924,  1.9099,  0.0343,  1.6747,  1.2596, -0.2227],\n",
      "        [ 0.2623, -0.3287,  1.0322, -0.5111, -0.2392,  1.1337,  0.1848,  0.3596,\n",
      "          0.4911, -1.0449, -0.6596,  1.0359, -0.4786,  2.0907,  0.2720],\n",
      "        [-0.9111,  0.5388, -0.0388, -0.9062, -1.2115, -1.7624, -0.6426, -2.1454,\n",
      "         -0.9097, -0.1549, -2.4633, -0.5267, -1.9401, -1.0004, -0.3105]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method item of Tensor object at 0x7fa45e295dc8>\n"
     ]
    }
   ],
   "source": [
    "print(W1.item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'is', 'a', 'king', 'she', 'queen', 'man', 'woman', 'warsaw', 'poland', 'capital', 'berlin', 'germany', 'paris', 'france']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6650, -0.6515,  1.7643, -0.6612, -0.5184,  0.1936, -0.7601,  1.1543,\n",
      "          0.0982,  1.0659,  1.0329,  0.8713, -1.1771,  1.2245, -0.0804],\n",
      "        [-0.7244,  0.0624,  0.6872, -0.3318, -0.5093,  0.6087, -0.5052,  1.7931,\n",
      "          0.3268, -0.1901,  0.4482, -0.5657, -2.5397, -0.2461, -1.9045],\n",
      "        [-1.6269, -0.6633, -0.5409, -0.9472, -1.5115, -0.0293, -1.1832, -0.0305,\n",
      "          0.3386, -1.2924,  1.9099,  0.0343,  1.6747,  1.2596, -0.2227],\n",
      "        [ 0.2623, -0.3287,  1.0322, -0.5111, -0.2392,  1.1337,  0.1848,  0.3596,\n",
      "          0.4911, -1.0449, -0.6596,  1.0359, -0.4786,  2.0907,  0.2720],\n",
      "        [-0.9111,  0.5388, -0.0388, -0.9062, -1.2115, -1.7624, -0.6426, -2.1454,\n",
      "         -0.9097, -0.1549, -2.4633, -0.5267, -1.9401, -1.0004, -0.3105]])\n"
     ]
    }
   ],
   "source": [
    "print(W1.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = W1.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.66498345 -0.7244271  -1.6269408   0.26228485 -0.9111005 ]\n",
      " [-0.65151286  0.06237222 -0.66330755 -0.32867888  0.5387854 ]\n",
      " [ 1.7643375   0.6872097  -0.5408893   1.0322185  -0.03879061]\n",
      " [-0.6611918  -0.3318367  -0.9471532  -0.51109403 -0.90621793]\n",
      " [-0.5184357  -0.5093096  -1.5115323  -0.23921917 -1.2114769 ]\n",
      " [ 0.19364242  0.6086715  -0.02925137  1.133663   -1.7624112 ]\n",
      " [-0.7601495  -0.5052044  -1.1832007   0.18479522 -0.6426129 ]\n",
      " [ 1.1543491   1.7930627  -0.03048167  0.35959837 -2.1454127 ]\n",
      " [ 0.09816273  0.32684568  0.33861876  0.49112305 -0.90969056]\n",
      " [ 1.0658635  -0.1900604  -1.2923604  -1.0449433  -0.15485954]\n",
      " [ 1.0328833   0.44815314  1.9099499  -0.6596172  -2.4632773 ]\n",
      " [ 0.8712858  -0.5656944   0.03429155  1.0358573  -0.526661  ]\n",
      " [-1.1771438  -2.5396633   1.6747174  -0.47864276 -1.9401181 ]\n",
      " [ 1.2244781  -0.24606352  1.2596201   2.0907245  -1.0003916 ]\n",
      " [-0.08039328 -1.9045221  -0.22272508  0.2720494  -0.31049582]]\n"
     ]
    }
   ],
   "source": [
    "print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.66498345 -0.7244271  -1.6269408   0.26228485 -0.9111005 ]\n"
     ]
    }
   ],
   "source": [
    "print(embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'is', 'a', 'king', 'she', 'queen', 'man', 'woman', 'warsaw', 'poland', 'capital', 'berlin', 'germany', 'paris', 'france']\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = {}\n",
    "for i in range(len(vocabulary)):\n",
    "    e[vocabulary[i]] = embedding[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6611918  -0.3318367  -0.9471532  -0.51109403 -0.90621793]\n"
     ]
    }
   ],
   "source": [
    "print(e['king'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89012814\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(e['he'], e['is']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding2 = W2.data.numpy()\n",
    "b = {}\n",
    "for i in range(len(vocabulary)):\n",
    "    b[vocabulary[i]] = embedding2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.487155  ,  0.43970457, -0.3071918 ,  0.3034896 ,  0.4648041 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['he']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.370908\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(b['poland'], b['poland']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-96774d4afd21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Create random input and output data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:6\") # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 3.], device='cuda:6')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:6\")\n",
    "dtype = torch.float\n",
    "test = torch.tensor([5, 3], device=device, dtype=dtype)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "embedding_dimension = 100\n",
    "dtype = torch.float\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:6\") # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, vocabulary_size, embedding_dimension, vocabulary_size\n",
    "\n",
    "# Create input and output data from idx_pairs\n",
    "x = []\n",
    "y = []\n",
    "for pair in idx_pairs:\n",
    "    cur_x = []\n",
    "    cur_y = []\n",
    "    for i in range(0, vocabulary_size):\n",
    "        if(i == pair[0]):\n",
    "            cur_x.append(1)\n",
    "        else:\n",
    "            cur_x.append(0)\n",
    "        if(i == pair[1]):\n",
    "            cur_y.append(1)\n",
    "        else:\n",
    "            cur_y.append(0)\n",
    "    x.append(cur_x)\n",
    "    y.append(cur_y)\n",
    "\n",
    "print(len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 15 15\n",
      "torch.Size([15, 100])\n",
      "0 42256.65234375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "                \n",
    "\n",
    "# # Create random input and output data\n",
    "# x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
    "# y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n",
    "print(H, D_in, D_out)\n",
    "learning_rate = 1e-3\n",
    "loss_val = 0\n",
    "for t in range(1):\n",
    "    # Forward pass: compute predicted y\n",
    "    for i in range(len(x)):\n",
    "        x_vector = torch.tensor(x[i], device=device, dtype=dtype)        \n",
    "        y_vector = torch.tensor(y[i], device=device, dtype=dtype)        \n",
    "        z1 = torch.matmul(w1, x)\n",
    "        z2 = torch.matmul(w2, z1)\n",
    "        log_softmax = F.log_softmax(z2, dim=0)\n",
    "        loss = F.nll_loss(log_softmax.view(1,-1), y_vector)\n",
    "        loss_val += loss.item()\n",
    "        loss.backward()\n",
    "#         print(w1.size())\n",
    "#         h_relu = h.clamp(min=0)\n",
    "#         y_pred = h_relu.mm(w2)\n",
    "\n",
    "        # Compute and print loss\n",
    "#         loss = (y_pred - y).pow(2).sum().item()\n",
    "        print(t, loss_val)\n",
    "        W1.data -= learning_rate * W1.grad.data\n",
    "        W2.data -= learning_rate * W2.grad.data\n",
    "\n",
    "        W1.grad.data.zero_()\n",
    "        W2.grad.data.zero_()\n",
    "\n",
    "        # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "#         grad_y_pred = 2.0 * (y_pred - y)\n",
    "#         grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "#         grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "#         grad_h = grad_h_relu.clone()\n",
    "#         grad_h[h < 0] = 0\n",
    "#         grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "#         # Update weights using gradient descent\n",
    "#         w1 -= learning_rate * grad_w1\n",
    "#         w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1420e-02,  6.1293e-01, -1.3923e-01, -1.8433e-02, -6.6051e-01,\n",
      "         1.1946e-01,  1.3269e+00, -5.1187e-02, -5.2783e-01, -1.3794e-01,\n",
      "        -9.5055e-02, -6.1692e-01, -1.9752e-01,  6.8335e-01,  6.0173e-01,\n",
      "        -1.2278e-01, -3.3696e-01, -2.2094e-01, -4.1712e-01, -7.6910e-01,\n",
      "        -5.6342e-01,  1.2546e-01,  7.3180e-01,  3.4895e-01,  1.6103e-01,\n",
      "        -1.7344e-01, -8.9016e-04,  7.0031e-02,  9.9244e-01, -7.3614e-01,\n",
      "        -9.4316e-01,  2.6637e-01, -6.9867e-01, -5.7772e-01, -4.3356e-01,\n",
      "        -1.4589e+00, -7.3039e-01, -1.5080e+00, -6.0735e-02,  1.0355e-01,\n",
      "        -2.2269e-01, -1.1411e+00, -1.6334e-01, -1.4689e+00, -3.1832e-01,\n",
      "        -1.7231e-01, -3.4880e-01, -1.3733e-01, -2.1905e-01,  7.7471e-01,\n",
      "         4.9175e-01,  5.5166e-01, -3.6932e-01,  4.7385e-01, -6.9067e-02,\n",
      "        -1.1892e-01, -2.2312e+00,  1.5254e-01, -5.2823e-02, -1.3127e+00,\n",
      "        -9.7139e-02, -1.1388e-01, -7.0674e-01, -7.9843e-02, -1.0846e+00,\n",
      "         7.5075e-01,  7.3198e-01, -7.9156e-01, -6.2829e-02, -7.8892e-01,\n",
      "        -1.2911e+00, -1.1714e-01, -1.0481e+00, -5.7731e-02, -1.9193e-02,\n",
      "         2.6836e-01,  4.5583e-01, -6.0798e-01,  1.1409e+00,  1.1897e+00,\n",
      "        -1.1454e-01, -3.6881e-01, -2.7615e-01, -5.3014e-01, -2.6818e-01,\n",
      "        -1.4057e-01, -7.5650e-01,  1.4195e-01, -7.1592e-01,  4.2864e-01,\n",
      "        -1.2410e-01,  5.1867e-01, -1.0417e-01, -3.5413e-01,  2.6051e-01,\n",
      "        -6.2556e-01,  1.2734e-01, -6.7777e-01,  7.0148e-02, -1.4558e-01],\n",
      "       device='cuda:6')\n"
     ]
    }
   ],
   "source": [
    "print(w1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
