{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "import string\n",
    "import re\n",
    "from random import randint\n",
    "import math\n",
    "import argparse, sys\n",
    "import time\n",
    "\n",
    "W = np.loadtxt('data/W_NEG_15_DIM_300_EPOCHS_500_t6.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28354"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(W[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineDistance(x, y):\n",
    "    s = np.dot(x,y)\n",
    "    s = s/((np.dot(x,x))**0.5)\n",
    "    s = s/((np.dot(y,y))**0.5)\n",
    "    return s\n",
    "\n",
    "def cosineDistanceString(s1, s2, W, word2id):\n",
    "    x = W[word2id[s1]]\n",
    "    y = W[word2id[s2]]\n",
    "    return cosineDistance(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readVocabulary(fileName):\n",
    "    f1 = open(fileName, \"r\")\n",
    "    vocab = {}\n",
    "    for line in f1:\n",
    "        v = line.strip().split('\\t')\n",
    "        vocab[v[0]] = int(v[1])\n",
    "    f1.close()\n",
    "    return vocab\n",
    "\n",
    "def readWord2id(fileName):\n",
    "    f1 = open(fileName, \"r\")\n",
    "    word2id = {}\n",
    "    for line in f1:\n",
    "        v = line.strip().split('\\t')\n",
    "        word2id[v[0]] = int(v[1])\n",
    "    f1.close()\n",
    "    return word2id\n",
    "\n",
    "def readId2word(fileName):\n",
    "    f1 = open(fileName, \"r\")\n",
    "    id2word = {}\n",
    "    for line in f1:\n",
    "        v = line.strip().split('\\t')\n",
    "        id2word[int(v[0])] = v[1]\n",
    "    f1.close()\n",
    "    return id2word\n",
    "\n",
    "def readAll():\n",
    "    vocab = readVocabulary('data/vocab_nonum.txt')\n",
    "    word2id = readWord2id('data/word2id_nonum.txt')\n",
    "    id2word = readId2word('data/id2word_nonum.txt')\n",
    "    return vocab, word2id, id2word\n",
    "\n",
    "def readAllPrevious():\n",
    "    vocab = readVocabulary('../data_word2vec/vocab.txt')\n",
    "    word2id = readWord2id('../data_word2vec/word2id.txt')\n",
    "    id2word = readId2word('../data_word2vec/id2word.txt')\n",
    "    return vocab, word2id, id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab, word2id, id2word = readAll()\n",
    "vocab, word2id, id2word = readAllPrevious()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34055"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = W.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_king = W[word2id['queen']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sure'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_eval = \"happy\"\n",
    "closest_word = ''\n",
    "closest_word_dist = -9999\n",
    "for i in range(len(W)):\n",
    "    word = id2word[i]\n",
    "    dist = cosineDistance(W[word2id[word_to_eval]], W[i])\n",
    "    if(dist > closest_word_dist and i != word2id[word_to_eval] and i != word2id['craft']):\n",
    "        closest_word_dist = dist\n",
    "        closest_word = word\n",
    "closest_word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2716479971217683"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosineDistanceString('good', 'planted', W, word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'###'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-46d1a393f67c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcosineDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'but'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'###'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '###'"
     ]
    }
   ],
   "source": [
    "cosineDistance(W[word2id['but']],W[word2id['###']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.loadtxt('data/C_NEG_15_DIM_300_EPOCHS_100_new.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClosest(word_to_eval, W, word2id, id2word):\n",
    "    closest_word = ''\n",
    "    closest_word_dist = -9999\n",
    "    for i in range(len(W)):\n",
    "        word = id2word[i]\n",
    "        dist = cosineDistance(W[word2id[word_to_eval]], W[i])\n",
    "        if(dist > closest_word_dist and i != word2id[word_to_eval]):\n",
    "            closest_word_dist = dist\n",
    "            closest_word = word\n",
    "    return closest_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTopK(word_to_eval, W, word2id, id2word):\n",
    "    dict = {}\n",
    "    for i in range(len(W)):\n",
    "        word = id2word[i]\n",
    "        dist = cosineDistance(W[word2id[word_to_eval]], W[i])\n",
    "        dict[word] = dist\n",
    "    sorted_by_value = sorted(dict.items(), key=lambda kv: kv[1])\n",
    "    return sorted_by_value[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trillion', 0.4583014189280814),\n",
       " ('dlrs', 0.45905711382575487),\n",
       " ('lire', 0.47225202870504757),\n",
       " ('mln', 0.5341607675289907),\n",
       " ('billion', 1.0)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = findTopK('billion', W, word2id, id2word)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'###'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b2ef6262f705>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcosineDistanceString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'but'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'###'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-ba688f5f734f>\u001b[0m in \u001b[0;36mcosineDistanceString\u001b[0;34m(s1, s2, W, word2id)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcosineDistanceString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcosineDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '###'"
     ]
    }
   ],
   "source": [
    "cosineDistanceString('but', '###', W, word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"SimLex-999.txt\", \"r\")\n",
    "scores = []\n",
    "i = 0\n",
    "for line in f:\n",
    "    i+= 1\n",
    "    if(i == 1):\n",
    "        continue\n",
    "    line = line.strip()\n",
    "    tokens = line.split('\\t')\n",
    "    sample = {}\n",
    "    sample['w1'] = tokens[0]\n",
    "    sample['w2'] = tokens[1]\n",
    "    sample['score'] = float(tokens[3])\n",
    "    if sample['w1'] in vocab and sample['w2'] in vocab:\n",
    "        scores.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10781761657232766"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "predicted_scores = []\n",
    "simlex_score = []\n",
    "for sample in scores:\n",
    "    w1 = sample['w1']\n",
    "    w2 = sample['w2']\n",
    "    predicted_scores.append(cosineDistanceString(w1, w2, W, word2id))\n",
    "    simlex_score.append(sample['score'])\n",
    "corr, p_value = spearmanr(simlex_score, predicted_scores)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.loadtxt('data/C_NEG_15_DIM_300_EPOCHS_100_cont2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = (W+C)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
