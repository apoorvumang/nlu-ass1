{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading pairs\n",
      "Reading vocab\n",
      "Creating array for negative sampling\n",
      "210795 28354 3846178\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "import string\n",
    "import re\n",
    "\n",
    "POWER_FOR_NEGATIVE_SAMPLING = 3.0/4.0\n",
    "\n",
    "def readPairs(fileName):\n",
    "    f1 = open(fileName, \"r\")\n",
    "    pairs = []\n",
    "    for line in f1:\n",
    "        pair = line.strip().split('\\t')\n",
    "        for i in range(len(pair)):\n",
    "            pair[i] = int(pair[i])\n",
    "        pairs.append(pair)\n",
    "    f1.close()\n",
    "    return pairs\n",
    "\n",
    "def readVocabulary(fileName):\n",
    "    f1 = open(fileName, \"r\")\n",
    "    vocab = {}\n",
    "    for line in f1:\n",
    "        v = line.strip().split('\\t')\n",
    "        vocab[v[0]] = int(v[1])\n",
    "    f1.close()\n",
    "    return vocab\n",
    "\n",
    "def readWord2id(fileName):\n",
    "    f1 = open(fileName, \"r\")\n",
    "    word2id = {}\n",
    "    for line in f1:\n",
    "        v = line.strip().split('\\t')\n",
    "        word2id[v[0]] = int(v[1])\n",
    "    f1.close()\n",
    "    return word2id\n",
    "\n",
    "def readId2word(fileName):\n",
    "    f1 = open(fileName, \"r\")\n",
    "    id2word = {}\n",
    "    for line in f1:\n",
    "        v = line.strip().split('\\t')\n",
    "        id2word[int(v[0])] = v[1]\n",
    "    f1.close()\n",
    "    return id2word\n",
    "\n",
    "def readAll():\n",
    "    vocab = readVocabulary('data/vocab.txt')\n",
    "    word2id = readWord2id('data/word2id.txt')\n",
    "    id2word = readId2word('data/id2word.txt')\n",
    "    return vocab, word2id, id2word\n",
    "\n",
    "def getArrForNegativeSampling(vocab):\n",
    "    idsForNegativeSampling = []\n",
    "    for word, count in vocab.items():\n",
    "        newCount = int(float(count)**(POWER_FOR_NEGATIVE_SAMPLING))\n",
    "        for i in range(newCount):\n",
    "            idsForNegativeSampling.append(word2id[word])\n",
    "    return idsForNegativeSampling\n",
    "\n",
    "print('Reading pairs')\n",
    "pairs = readPairs('data/pairs.txt')\n",
    "print('Reading vocab')\n",
    "vocab, word2id, id2word = readAll()\n",
    "print('Creating array for negative sampling')\n",
    "idsForNegativeSampling = getArrForNegativeSampling(vocab)\n",
    "\n",
    "print(len(idsForNegativeSampling), len(vocab), len(pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective -369.8252819183574\n",
      "Objective -1.6748379580564048\n",
      "Objective -32.62534923103328\n",
      "Objective -175.52861258024123\n",
      "Objective -3.450468532406376\n",
      "Objective -5.659135652950759\n",
      "Objective -4.040083856615707\n",
      "Objective -5.964640579071141\n",
      "Objective -2.678388467662326\n",
      "Objective -2.5711952051984723\n",
      "Objective -4.868586832908714\n",
      "Objective -0.6630235259460455\n",
      "Objective -2.2298155173539036\n",
      "Objective -16.844441440965376\n",
      "Objective -4.625695351542134\n",
      "Objective -1.5050016958831467\n",
      "Objective -18.387213341118567\n",
      "Objective -1.8898147541217238\n",
      "Objective -3.779517477666791\n",
      "Objective -2.4444869606725184\n",
      "Objective -203.64208394185607\n",
      "Objective -1.5048944933825112\n",
      "Objective -2.2845700434239444\n",
      "Objective -1.270336947384752\n",
      "Objective -1.614033635185388\n",
      "Objective -2.403228995327174\n",
      "Objective -2.7559393050130088\n",
      "Objective -2.342123598522421\n",
      "Objective -2.4177319499149417\n",
      "Objective -3.802688909546072\n",
      "Objective -2.786153558625191\n",
      "Objective -57.057923604437185\n",
      "Objective -111.62183729837318\n",
      "Objective -3.505890864421147\n",
      "Objective -204.57090389185467\n",
      "Objective -3.076895806763433\n",
      "Objective -7.770396593803089\n",
      "Objective -5.82869902519123\n",
      "Objective -2.5827342006287983\n",
      "Objective -7.179738475083155\n",
      "Objective -1.836238701314049\n",
      "Objective -77.47830570958874\n",
      "Objective -3.10149505874735\n",
      "Objective -1.4166519833478908\n",
      "Objective -1.4648780039239273\n",
      "Objective -6.717071151260761\n",
      "Objective -1.953052141336786\n",
      "Objective -3.2621637473108303\n",
      "Objective -2.5914065393248342\n",
      "Objective -1.8318219849857176\n",
      "Objective -1.596078208952071\n",
      "Objective -23.902569603765585\n",
      "Objective -3.694598250486815\n",
      "Objective -1.7071010420054895\n",
      "Objective -7.010175211577207\n",
      "Objective -1.2245102439994937\n",
      "Objective -1.7443443502486173\n",
      "Objective -0.11682790123907072\n",
      "Objective -62.69863320749297\n",
      "Objective -0.175746049767638\n",
      "Objective -2.08771995731404\n",
      "Objective -3.1711983983217964\n",
      "Objective -1.456951852546037\n"
     ]
    }
   ],
   "source": [
    "# logic for training:\n",
    "# create random matrics W and C\n",
    "# W: centre word embedding: d x vocab_size\n",
    "# C: context word embedding: vocab_size x d\n",
    "from random import randint\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "EMBEDDING_DIMENSION = 300\n",
    "LR = 0.01\n",
    "NUM_NEGATIVE_SAMPLES = 5\n",
    "W = np.random.rand(EMBEDDING_DIMENSION, vocab_size)\n",
    "C = np.random.rand(vocab_size, EMBEDDING_DIMENSION)\n",
    "for epoch in range(100):\n",
    "    numDone = 0\n",
    "    for pair in pairs:\n",
    "        a = int(pair[0]) # centre word id\n",
    "        b = int(pair[1]) # context word id\n",
    "\n",
    "        n = [] # to store negative context word ids\n",
    "        for i in range(NUM_NEGATIVE_SAMPLES):\n",
    "            x = randint(0, len(idsForNegativeSampling)-1)\n",
    "            n.append(idsForNegativeSampling[x])\n",
    "        \n",
    "        # n now stores ids for negative samples\n",
    "        wa = W.T[a]\n",
    "        # get gradient for wa\n",
    "        sigCbwa = sigmoid(np.dot(C[b], wa))\n",
    "        gradwa = (1.0 - sigCbwa)*C[b]\n",
    "        sigminusCniwa = {}\n",
    "        for id in n:\n",
    "            sigminusCniwa[id] = sigmoid(np.dot(-C[id], wa))\n",
    "            gradwa += (sigminusCniwa[id] - 1.0)*C[id]\n",
    "            \n",
    "        # update context embedding for positive sample:\n",
    "        C[b] += LR*(1.0 - sigCbwa)*wa\n",
    "        \n",
    "        #update context embedding for negative samples:\n",
    "        for id in n:\n",
    "            C[id] += LR*(sigminusCniwa[id] - 1.0)*wa\n",
    "        #update wa\n",
    "        W.T[a] += LR*gradwa\n",
    "        CUR_OBJECTIVE = math.log(sigCbwa)\n",
    "        for id in n:\n",
    "            CUR_OBJECTIVE += math.log(sigminusCniwa[id])\n",
    "        if(numDone%10000 == 0):\n",
    "            print('Objective', CUR_OBJECTIVE)\n",
    "        numDone += 1\n",
    "    print('Epoch done', epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
