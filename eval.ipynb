{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "import string\n",
    "import re\n",
    "from random import randint\n",
    "import math\n",
    "import argparse, sys\n",
    "import time\n",
    "\n",
    "# W = np.loadtxt('data/W_NEG_20_DIM_300_EPOCHS_50_nonum_full_win3.txt')\n",
    "npz = np.load('data/W_NEG_20_DIM_300_EPOCHS_25_nonum_full_win3_epoch75.npy.npz')\n",
    "W = npz['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34055"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numTokens = 0\n",
    "len(vocab)\n",
    "# for key, value in vocab.items():\n",
    "#     numTokens += value\n",
    "# numTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afsdfsafsdf.\n",
      "-----\n",
      "dr. sdf sdf sf sdf .\n"
     ]
    }
   ],
   "source": [
    "import nltk.data\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "data = \"afsdfsafsdf. dr. sdf sdf sf sdf .\"\n",
    "print('\\n-----\\n'.join(tokenizer.tokenize(data)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34055"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(W[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineDistance(x, y):\n",
    "    s = np.dot(x,y)\n",
    "    s = s/((np.dot(x,x))**0.5)\n",
    "    s = s/((np.dot(y,y))**0.5)\n",
    "    return s\n",
    "\n",
    "def cosineDistanceString(s1, s2, W, word2id):\n",
    "    x = W[word2id[s1]]\n",
    "    y = W[word2id[s2]]\n",
    "    return cosineDistance(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readVocabulary(fileName):\n",
    "    f1 = open(fileName, \"r\")\n",
    "    vocab = {}\n",
    "    for line in f1:\n",
    "        v = line.strip().split('\\t')\n",
    "        vocab[v[0]] = int(v[1])\n",
    "    f1.close()\n",
    "    return vocab\n",
    "\n",
    "def readWord2id(fileName):\n",
    "    f1 = open(fileName, \"r\")\n",
    "    word2id = {}\n",
    "    for line in f1:\n",
    "        v = line.strip().split('\\t')\n",
    "        word2id[v[0]] = int(v[1])\n",
    "    f1.close()\n",
    "    return word2id\n",
    "\n",
    "def readId2word(fileName):\n",
    "    f1 = open(fileName, \"r\")\n",
    "    id2word = {}\n",
    "    for line in f1:\n",
    "        v = line.strip().split('\\t')\n",
    "        id2word[int(v[0])] = v[1]\n",
    "    f1.close()\n",
    "    return id2word\n",
    "\n",
    "def readAllHashnum():\n",
    "    vocab = readVocabulary('data/vocab_hashnum.txt')\n",
    "    word2id = readWord2id('data/word2id_hashnum.txt')\n",
    "    id2word = readId2word('data/id2word_hashnum.txt')\n",
    "    return vocab, word2id, id2word\n",
    "\n",
    "def readAllNonum():\n",
    "    vocab = readVocabulary('data/vocab_nonum.txt')\n",
    "    word2id = readWord2id('data/word2id_nonum.txt')\n",
    "    id2word = readId2word('data/id2word_nonum.txt')\n",
    "    return vocab, word2id, id2word\n",
    "\n",
    "\n",
    "def readAllPrevious():\n",
    "    vocab = readVocabulary('../data_word2vec/vocab.txt')\n",
    "    word2id = readWord2id('../data_word2vec/word2id.txt')\n",
    "    id2word = readId2word('../data_word2vec/id2word.txt')\n",
    "    return vocab, word2id, id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, word2id, id2word = readAllNonum()\n",
    "# vocab, word2id, id2word = readAllPrevious()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34055"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = W.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_king = W[word2id['queen']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sure'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_eval = \"happy\"\n",
    "closest_word = ''\n",
    "closest_word_dist = -9999\n",
    "for i in range(len(W)):\n",
    "    word = id2word[i]\n",
    "    dist = cosineDistance(W[word2id[word_to_eval]], W[i])\n",
    "    if(dist > closest_word_dist and i != word2id[word_to_eval] and i != word2id['craft']):\n",
    "        closest_word_dist = dist\n",
    "        closest_word = word\n",
    "closest_word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14825886183046774"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosineDistanceString('good', 'planted', C, word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'###'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-46d1a393f67c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcosineDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'but'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'###'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '###'"
     ]
    }
   ],
   "source": [
    "cosineDistance(W[word2id['but']],W[word2id['###']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.loadtxt('data/C_NEG_15_DIM_300_EPOCHS_100_new.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClosest(word_to_eval, W, word2id, id2word):\n",
    "    closest_word = ''\n",
    "    closest_word_dist = -9999\n",
    "    for i in range(len(W)):\n",
    "        word = id2word[i]\n",
    "        dist = cosineDistance(W[word2id[word_to_eval]], W[i])\n",
    "        if(dist > closest_word_dist and i != word2id[word_to_eval]):\n",
    "            closest_word_dist = dist\n",
    "            closest_word = word\n",
    "    return closest_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTopK(word_to_eval, W, word2id, id2word):\n",
    "    dict = {}\n",
    "    for i in range(len(W)):\n",
    "        word = id2word[i]\n",
    "        dist = cosineDistance(W[word2id[word_to_eval]], W[i])\n",
    "        dict[word] = dist\n",
    "    sorted_by_value = sorted(dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    return sorted_by_value[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "women\n",
      "martell\n",
      "wk\n",
      "stabilized\n",
      "lived\n",
      "ceremony\n",
      "rafsanjani\n",
      "rio\n",
      "bbls\n",
      "macandrews\n",
      "cadillac\n",
      "refer\n",
      "returning\n",
      "denver\n",
      "wellemeyer\n",
      "13-week\n",
      "ivaco\n",
      "alvite\n",
      "milds\n",
      "barber\n"
     ]
    }
   ],
   "source": [
    "wordToFindClosest = 'women'\n",
    "ans = findTopK(wordToFindClosest, C, word2id, id2word)\n",
    "print(wordToFindClosest)\n",
    "for a in ans:\n",
    "    print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19075806151222577"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosineDistanceString('white', 'killed', C, word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def evalSimlex(W, vocab):\n",
    "    f = open(\"SimLex-999.txt\", \"r\")\n",
    "    scores = []\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        i+= 1\n",
    "        if(i == 1):\n",
    "            continue\n",
    "        line = line.strip()\n",
    "        tokens = line.split('\\t')\n",
    "        sample = {}\n",
    "        sample['w1'] = tokens[0]\n",
    "        sample['w2'] = tokens[1]\n",
    "        sample['score'] = float(tokens[3])\n",
    "        if sample['w1'] in vocab and sample['w2'] in vocab:\n",
    "            scores.append(sample)\n",
    "    predicted_scores = []\n",
    "    simlex_score = []\n",
    "    for sample in scores:\n",
    "        w1 = sample['w1']\n",
    "        w2 = sample['w2']\n",
    "        predicted_scores.append(cosineDistanceString(w1, w2, W, word2id))\n",
    "        simlex_score.append(sample['score'])\n",
    "    corr, p_value = spearmanr(simlex_score, predicted_scores)\n",
    "    return corr\n",
    "\n",
    "def evalWordsim(W, vocab):\n",
    "    f = open(\"data/wordsim.txt\", \"r\")\n",
    "    scores = []\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        i+= 1\n",
    "        if(i == 1):\n",
    "            continue\n",
    "        line = line.strip()\n",
    "        tokens = line.split('\\t')\n",
    "        sample = {}\n",
    "        sample['w1'] = tokens[0]\n",
    "        sample['w2'] = tokens[1]\n",
    "        sample['score'] = float(tokens[2])\n",
    "        if sample['w1'] in vocab and sample['w2'] in vocab:\n",
    "            scores.append(sample)\n",
    "    predicted_scores = []\n",
    "    wordsim_score = []\n",
    "    for sample in scores:\n",
    "        w1 = sample['w1']\n",
    "        w2 = sample['w2']\n",
    "        predicted_scores.append(cosineDistanceString(w1, w2, W, word2id))\n",
    "        wordsim_score.append(sample['score'])\n",
    "    corr, p_value = spearmanr(wordsim_score, predicted_scores)\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('data/W_NEG_20_DIM_300_EPOCHS_25_nonum_full_win3_epoch75.npy.npz')\n",
    "W = npz['arr_0']\n",
    "npz = np.load('data/C_NEG_20_DIM_300_EPOCHS_25_nonum_full_win3_epoch75.npy.npz')\n",
    "C = npz['arr_0']\n",
    "\n",
    "# W = np.loadtxt('data/W_NEG_15_DIM_300_EPOCHS_500_t6.txt')\n",
    "# C = np.loadtxt('data/C_NEG_15_DIM_300_EPOCHS_500_t6.txt')\n",
    "W=W.T\n",
    "WC = np.concatenate((W, C), axis = 1)\n",
    "vocab, word2id, id2word = readAllNonum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34055"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W\n",
      "Simlex 0.121804617502587\n",
      "Wordsim 0.20161243598711406\n",
      "C\n",
      "Simlex 0.13953518501066306\n",
      "Wordsim 0.30418429005041586\n",
      "Avg\n",
      "Simlex 0.10508361488406495\n",
      "Wordsim 0.2772922755589194\n",
      "Concatenated\n",
      "Simlex 0.15152822358615842\n",
      "Wordsim 0.2872126820051131\n"
     ]
    }
   ],
   "source": [
    "print('W')\n",
    "print('Simlex', evalSimlex(W, vocab))\n",
    "print('Wordsim', evalWordsim(W, vocab))\n",
    "\n",
    "print('C')\n",
    "print('Simlex', evalSimlex(C, vocab))\n",
    "print('Wordsim', evalWordsim(C, vocab))\n",
    "\n",
    "print('Avg')\n",
    "print('Simlex', evalSimlex((W+C)/2, vocab))\n",
    "print('Wordsim', evalWordsim((W+C)/2, vocab))\n",
    "\n",
    "print('Concatenated')\n",
    "print('Simlex', evalSimlex(WC, vocab))\n",
    "print('Wordsim', evalWordsim(WC, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(WC[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.011782604157235591"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosineDistance(C[1], W[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69245"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20048"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numGood = 0\n",
    "for key, value in vocab.items():\n",
    "    if(value >= 2):\n",
    "        numGood+= 1\n",
    "numGood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
